{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO en Tiempo Real: Detección de Objetos\n",
    "### Percepción Computacional - Universidad de los Hemisferios\n",
    "#### Maestría en Inteligencia Artificial Aplicada\n",
    "\n",
    "Bienvenidos a este cuaderno de Jupyter, donde exploraremos la emocionante tarea de la detección de objetos en tiempo real utilizando YOLO (You Only Look Once), una técnica avanzada de visión por computadora. Esta experiencia de aprendizaje forma parte del programa de la Maestría en Inteligencia Artificial Aplicada, impartido por la Universidad de los Hemisferios.\n",
    "\n",
    "En este cuaderno, aprenderás a utilizar YOLO para identificar y localizar diversos objetos en imágenes y secuencias de video. Esta habilidad es esencial en una amplia gama de aplicaciones, desde la conducción autónoma hasta la vigilancia de seguridad, y representa uno de los avances más emocionantes en el campo de la inteligencia artificial y la visión por computadora.\n",
    "\n",
    "A lo largo de este curso, explorarás conceptos clave como:\n",
    "\n",
    "- Detección de objetos en tiempo real.\n",
    "- Configuración de modelos YOLO pre-entrenados.\n",
    "- Interpretación de resultados de detección.\n",
    "- Aplicaciones prácticas de la detección de objetos.\n",
    "\n",
    "¡Prepárate para sumergirte en un emocionante mundo de visión por computadora y adquirir habilidades valiosas que te servirán en tu carrera en inteligencia artificial y más allá!\n",
    "\n",
    "Recuerda consultar este cuaderno para acceder a los recursos y ejemplos que te ayudarán a comprender YOLO y la percepción computacional en tiempo real.\n",
    "\n",
    "Eugenio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código utiliza el comando `!pip` para instalar dos paquetes de Python: `opencv-python` y `ultralytics`.\n",
    "\n",
    "- `opencv-python`: Esta es una biblioteca popular para tareas de visión por computadora en Python. Proporciona una variedad de funciones para el procesamiento de imágenes y videos, incluyendo detección de objetos, manipulación de imágenes y extracción de características.\n",
    "\n",
    "- `ultralytics`: Esta es una biblioteca construida sobre PyTorch, que se enfoca principalmente en tareas de visión por computadora como detección de objetos y clasificación de imágenes. Proporciona interfaces fáciles de usar para entrenar y evaluar modelos de aprendizaje profundo para estas tareas.\n",
    "\n",
    "Al ejecutar este comando, estás instalando estos paquetes en tu entorno de Python para que puedas usarlos en tu código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/bin/pip\", line 7, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
      "    from pip._internal.build_env import get_runnable_pip\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_internal/build_env.py\", line 15, in <module>\n",
      "    from pip._vendor.packaging.requirements import Requirement\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_vendor/packaging/requirements.py\", line 10, in <module>\n",
      "    from pip._vendor.pyparsing import (  # noqa\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_vendor/pyparsing/__init__.py\", line 132, in <module>\n",
      "    from .core import __diag__, __compat__\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_vendor/pyparsing/core.py\", line 6089, in <module>\n",
      "    _builtin_exprs: List[ParserElement] = [\n",
      "                                          ^\n",
      "  File \"/Users/eugenio/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/pip/_vendor/pyparsing/core.py\", line 6090, in <listcomp>\n",
      "    v for v in vars().values() if isinstance(v, ParserElement)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen abc>\", line 119, in __instancecheck__\n",
      "  File \"<frozen abc>\", line 123, in __subclasscheck__\n",
      "  File \"<frozen abc>\", line 123, in __subclasscheck__\n",
      "  File \"<frozen abc>\", line 123, in __subclasscheck__\n",
      "  [Previous line repeated 2 more times]\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Instalamos las librerías necesarias\n",
    "!pip install opencv-python ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código importa tres bibliotecas en Python:\n",
    "\n",
    "1. `ultralytics`: Esta es una biblioteca que proporciona una interfaz para usar modelos de detección de objetos YOLO (You Only Look Once). Permite entrenar, evaluar y utilizar modelos de detección de objetos de manera eficiente.\n",
    "\n",
    "2. `cv2` (OpenCV): Esta es una biblioteca popular para el procesamiento de imágenes y videos en Python. Proporciona una amplia gama de funciones para trabajar con imágenes y videos, incluyendo cargar imágenes, realizar operaciones de procesamiento de imágenes, y mostrar imágenes en una ventana, entre otros.\n",
    "\n",
    "3. `math`: Este es un módulo estándar de Python que proporciona funciones matemáticas comunes, como funciones trigonométricas, logarítmicas y aritméticas.\n",
    "\n",
    "El código importa estas bibliotecas para utilizarlas en el resto del programa, pero en este fragmento específico no se están utilizando ninguna función o clase de estas bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolo-Weights/yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.23M/6.23M [00:04<00:00, 1.38MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el modelo YOLO pre-entrenado en COCO dataset\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos las clases que puede detectar el modelo\n",
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una lista de nombres con todas las clases para identificar objetos detectados\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ] # Aquí se enumeran todas las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 21:17:54.900 Python[88688:5245434] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 214.1ms\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Speed: 8.2ms preprocess, 214.1ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 21:18:03.647 Python[88688:5245434] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 190.3ms\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 2.3ms preprocess, 190.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 475.0ms\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Speed: 2.3ms preprocess, 475.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 174.1ms\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Speed: 4.6ms preprocess, 174.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 172.1ms\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Speed: 5.0ms preprocess, 172.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 211.0ms\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 1.9ms preprocess, 211.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 152.5ms\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Speed: 2.1ms preprocess, 152.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.6ms\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 141.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.2ms\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 141.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 154.9ms\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 154.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 152.9ms\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 3.1ms preprocess, 152.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 137.4ms\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 137.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 137.8ms\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 137.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 138.9ms\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 138.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 138.5ms\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 138.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 139.7ms\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 139.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 138.4ms\n",
      "Speed: 1.5ms preprocess, 138.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.7ms\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 136.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.1ms\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 135.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.1ms\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 136.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.0ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 137.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.6ms\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 148.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.6ms\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 136.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.9ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 135.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.8ms\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 135.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 scissors, 135.5ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 135.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 scissors, 136.5ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 136.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 sink, 1 scissors, 140.2ms\n",
      "Confidence ---> 0.96\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> sink\n",
      "Speed: 1.8ms preprocess, 140.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 scissors, 140.0ms\n",
      "Confidence ---> 0.97\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 140.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 scissors, 136.8ms\n",
      "Confidence ---> 0.96\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 136.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 sink, 1 scissors, 135.9ms\n",
      "Confidence ---> 0.96\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> sink\n",
      "Speed: 1.5ms preprocess, 135.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 1 scissors, 199.0ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> cell phone\n",
      "Speed: 1.8ms preprocess, 199.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 cell phone, 1 scissors, 169.6ms\n",
      "Confidence ---> 0.96\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> mouse\n",
      "Speed: 1.9ms preprocess, 169.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 cell phone, 1 sink, 1 scissors, 138.6ms\n",
      "Confidence ---> 0.96\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.44\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.26\n",
      "Class name --> sink\n",
      "Speed: 2.6ms preprocess, 138.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 sink, 1 scissors, 137.0ms\n",
      "Confidence ---> 0.98\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.28\n",
      "Class name --> sink\n",
      "Speed: 1.5ms preprocess, 137.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 cell phone, 1 sink, 1 scissors, 137.3ms\n",
      "Confidence ---> 0.97\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.26\n",
      "Class name --> sink\n",
      "Speed: 1.6ms preprocess, 137.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 sink, 1 scissors, 138.7ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> sink\n",
      "Speed: 1.7ms preprocess, 138.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 sink, 1 scissors, 133.9ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> sink\n",
      "Confidence ---> 0.4\n",
      "Class name --> suitcase\n",
      "Speed: 1.4ms preprocess, 133.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 sink, 1 scissors, 136.8ms\n",
      "Confidence ---> 0.97\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> sink\n",
      "Confidence ---> 0.34\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 136.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 sink, 1 scissors, 135.8ms\n",
      "Confidence ---> 0.96\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.4\n",
      "Class name --> sink\n",
      "Speed: 1.6ms preprocess, 135.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 sink, 1 scissors, 136.2ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.31\n",
      "Class name --> sink\n",
      "Speed: 1.7ms preprocess, 136.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 1 scissors, 135.1ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.68\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 135.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 cell phone, 1 scissors, 135.6ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.64\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 135.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 cell phone, 1 scissors, 135.0ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.82\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> mouse\n",
      "Speed: 1.4ms preprocess, 135.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 cell phone, 1 scissors, 140.3ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.74\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 140.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 cell phone, 1 scissors, 135.7ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> suitcase\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.32\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 135.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 cell phone, 1 scissors, 136.6ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.29\n",
      "Class name --> suitcase\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "Speed: 1.5ms preprocess, 136.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 cell phone, 1 scissors, 135.6ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.33\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 135.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 mouse, 1 cell phone, 1 scissors, 136.4ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.78\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 136.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 mouse, 1 scissors, 135.3ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 135.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 mouse, 1 scissors, 137.1ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 137.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 mouse, 1 scissors, 133.8ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 133.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 134.6ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.32\n",
      "Class name --> suitcase\n",
      "Speed: 1.5ms preprocess, 134.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 scissors, 139.4ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 139.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 scissors, 136.9ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 136.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 135.7ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.3\n",
      "Class name --> suitcase\n",
      "Speed: 1.4ms preprocess, 135.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 scissors, 136.8ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 136.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 scissors, 137.0ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 137.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 136.0ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.29\n",
      "Class name --> suitcase\n",
      "Speed: 1.9ms preprocess, 136.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 mouse, 1 scissors, 135.9ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 135.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 136.0ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.32\n",
      "Class name --> suitcase\n",
      "Speed: 1.5ms preprocess, 136.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 136.7ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.39\n",
      "Class name --> suitcase\n",
      "Speed: 1.5ms preprocess, 136.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 136.8ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.35\n",
      "Class name --> suitcase\n",
      "Speed: 1.6ms preprocess, 136.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 135.8ms\n",
      "Confidence ---> 0.95\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.35\n",
      "Class name --> suitcase\n",
      "Speed: 1.5ms preprocess, 135.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 139.4ms\n",
      "Confidence ---> 0.94\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.34\n",
      "Class name --> suitcase\n",
      "Speed: 1.4ms preprocess, 139.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 148.4ms\n",
      "Confidence ---> 0.92\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.44\n",
      "Class name --> suitcase\n",
      "Speed: 1.8ms preprocess, 148.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 136.8ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.5\n",
      "Class name --> suitcase\n",
      "Speed: 1.5ms preprocess, 136.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 135.6ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.49\n",
      "Class name --> suitcase\n",
      "Speed: 1.5ms preprocess, 135.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 138.1ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.52\n",
      "Class name --> suitcase\n",
      "Speed: 1.6ms preprocess, 138.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 136.0ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.5\n",
      "Class name --> suitcase\n",
      "Speed: 1.6ms preprocess, 136.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 135.5ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> suitcase\n",
      "Confidence ---> 0.55\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 135.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 1 mouse, 1 scissors, 137.9ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.45\n",
      "Class name --> suitcase\n",
      "Speed: 1.4ms preprocess, 137.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 1 mouse, 1 scissors, 136.9ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.65\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> donut\n",
      "Speed: 1.4ms preprocess, 136.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 134.7ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> apple\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 134.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 138.2ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> apple\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 138.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 136.1ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> apple\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 136.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 1 scissors, 136.1ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> apple\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> scissors\n",
      "Speed: 1.6ms preprocess, 136.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 1 scissors, 136.7ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> apple\n",
      "Confidence ---> 0.73\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> scissors\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 136.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 1 scissors, 135.1ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> apple\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.54\n",
      "Class name --> scissors\n",
      "Speed: 1.5ms preprocess, 135.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 136.3ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> apple\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 136.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 apples, 1 mouse, 138.2ms\n",
      "Confidence ---> 0.82\n",
      "Class name --> apple\n",
      "Confidence ---> 0.59\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> apple\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 138.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 apple, 1 mouse, 135.3ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> apple\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 135.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 135.9ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> mouse\n",
      "Speed: 1.4ms preprocess, 135.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 139.8ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> apple\n",
      "Confidence ---> 0.65\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 139.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 136.1ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> apple\n",
      "Confidence ---> 0.52\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 136.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 136.3ms\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> apple\n",
      "Confidence ---> 0.62\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 136.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 139.2ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> apple\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 139.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 136.5ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> apple\n",
      "Confidence ---> 0.65\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 136.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 137.1ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> apple\n",
      "Confidence ---> 0.62\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 137.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 138.1ms\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> apple\n",
      "Confidence ---> 0.62\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 138.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 137.6ms\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> apple\n",
      "Confidence ---> 0.58\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 137.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 136.4ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> apple\n",
      "Confidence ---> 0.6\n",
      "Class name --> mouse\n",
      "Speed: 1.4ms preprocess, 136.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 138.4ms\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> apple\n",
      "Confidence ---> 0.63\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 138.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 136.0ms\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> apple\n",
      "Confidence ---> 0.65\n",
      "Class name --> mouse\n",
      "Speed: 1.4ms preprocess, 136.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 136.3ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> apple\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 136.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 135.4ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> apple\n",
      "Confidence ---> 0.58\n",
      "Class name --> mouse\n",
      "Speed: 1.4ms preprocess, 135.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 135.8ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> apple\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 135.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 157.5ms\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> apple\n",
      "Confidence ---> 0.63\n",
      "Class name --> mouse\n",
      "Speed: 1.8ms preprocess, 157.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 148.1ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> apple\n",
      "Confidence ---> 0.63\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 148.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 137.6ms\n",
      "Confidence ---> 0.78\n",
      "Class name --> apple\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> mouse\n",
      "Speed: 1.8ms preprocess, 137.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 138.7ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> apple\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> mouse\n",
      "Speed: 1.5ms preprocess, 138.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 139.2ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> apple\n",
      "Confidence ---> 0.6\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 139.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 140.1ms\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> apple\n",
      "Confidence ---> 0.54\n",
      "Class name --> mouse\n",
      "Speed: 2.0ms preprocess, 140.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 142.2ms\n",
      "Confidence ---> 0.78\n",
      "Class name --> apple\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> mouse\n",
      "Speed: 1.7ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 143.4ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> apple\n",
      "Confidence ---> 0.57\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 143.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 142.5ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> apple\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.47\n",
      "Class name --> cell phone\n",
      "Speed: 1.7ms preprocess, 142.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 140.8ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> apple\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "Speed: 1.6ms preprocess, 140.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 141.2ms\n",
      "Confidence ---> 0.8\n",
      "Class name --> apple\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "Speed: 1.6ms preprocess, 141.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 138.5ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> apple\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 138.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 139.5ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.48\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.34\n",
      "Class name --> laptop\n",
      "Speed: 1.5ms preprocess, 139.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 140.9ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> apple\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.38\n",
      "Class name --> cell phone\n",
      "Speed: 1.5ms preprocess, 140.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 141.7ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.49\n",
      "Class name --> mouse\n",
      "Speed: 1.6ms preprocess, 141.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 139.7ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> apple\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.36\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.27\n",
      "Class name --> laptop\n",
      "Speed: 1.5ms preprocess, 139.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 142.8ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.35\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Speed: 1.5ms preprocess, 142.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 142.5ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.37\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.27\n",
      "Class name --> laptop\n",
      "Speed: 1.8ms preprocess, 142.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 142.1ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.43\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.29\n",
      "Class name --> laptop\n",
      "Speed: 1.9ms preprocess, 142.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 142.3ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.48\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.27\n",
      "Class name --> laptop\n",
      "Speed: 1.8ms preprocess, 142.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 144.6ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.33\n",
      "Class name --> laptop\n",
      "Speed: 1.6ms preprocess, 144.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 140.8ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> apple\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.43\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.31\n",
      "Class name --> laptop\n",
      "Speed: 1.6ms preprocess, 140.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 142.6ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.41\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.27\n",
      "Class name --> laptop\n",
      "Speed: 1.5ms preprocess, 142.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 146.2ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.29\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.29\n",
      "Class name --> cell phone\n",
      "Speed: 1.5ms preprocess, 146.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 143.2ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> apple\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.37\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.3\n",
      "Class name --> laptop\n",
      "Speed: 1.6ms preprocess, 143.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 147.8ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> apple\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.36\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "Speed: 1.6ms preprocess, 147.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 150.4ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> apple\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.41\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "Speed: 1.8ms preprocess, 150.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 157.4ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> apple\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.47\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.31\n",
      "Class name --> laptop\n",
      "Speed: 1.7ms preprocess, 157.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 146.8ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.32\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Speed: 1.8ms preprocess, 146.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 155.1ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.28\n",
      "Class name --> laptop\n",
      "Speed: 1.6ms preprocess, 155.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 152.9ms\n",
      "Confidence ---> 0.82\n",
      "Class name --> apple\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "Speed: 1.6ms preprocess, 152.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 157.2ms\n",
      "Confidence ---> 0.83\n",
      "Class name --> apple\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.37\n",
      "Class name --> laptop\n",
      "Speed: 1.6ms preprocess, 157.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 147.8ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.31\n",
      "Class name --> laptop\n",
      "Speed: 1.6ms preprocess, 147.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 156.7ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.51\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> laptop\n",
      "Speed: 1.5ms preprocess, 156.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 151.8ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> apple\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.47\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.37\n",
      "Class name --> laptop\n",
      "Speed: 2.1ms preprocess, 151.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 147.1ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> apple\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> laptop\n",
      "Speed: 1.8ms preprocess, 147.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 146.9ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> apple\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.38\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.32\n",
      "Class name --> laptop\n",
      "Speed: 1.6ms preprocess, 146.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 151.3ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> apple\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.36\n",
      "Class name --> mouse\n",
      "Confidence ---> 0.33\n",
      "Class name --> laptop\n",
      "Speed: 1.8ms preprocess, 151.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Configuramos la captura de video desde la cámara\n",
    "captura = cv2.VideoCapture(0) # Se abre la cámara por defecto\n",
    "\n",
    "# Establecemos el ancho y alto de la imagen\n",
    "captura.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # Ancho de la imagen\n",
    "captura.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # Alto de la imagen\n",
    "\n",
    "# Iniciamos un bucle para procesar los fotogramas de la cámara\n",
    "while True:\n",
    "    success, img = captura.read() # Capturamos un fotograma\n",
    "\n",
    "    # Realizamos la detección de objetos en la imagen capturada (usando el modelo de YOLO pre-entrenado que cargamos anteriormente)\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "   # Procesamos los resultados de la detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Iteramos sobre las cajas delimitadoras detectadas\n",
    "        for box in boxes:\n",
    "            # Obtenemos las coordenadas de la caja delimitadora\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # Convertimos a valores enteros\n",
    "\n",
    "            # Dibujamos la caja delimitadora en la imagen\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)\n",
    "\n",
    "            # Obtenemos la confianza de la detección\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # Obtenemos el nombre de la clase detectada\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # Mostramos el nombre de la clase junto a la caja delimitadora\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0) # Color: Azul (formato BGR)\n",
    "            thickness = 1\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    # Mostramos la imagen con las detecciones\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # Salimos del bucle si se presiona la tecla 'q'\n",
    "    #if cv2.waitKey(1) == ord('q'):\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la cámara y cerramos todas las ventanas\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de índices de clases de interés\n",
    "clases_interes = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 apple, 185.4ms\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Speed: 6.9ms preprocess, 185.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 171.9ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 3.6ms preprocess, 171.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 cell phone, 147.2ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 147.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 158.4ms\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 158.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 153.8ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 153.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 164.6ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 3.2ms preprocess, 164.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 163.9ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 163.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 148.6ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 148.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 144.6ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 144.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 146.5ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 146.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 145.8ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 145.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 145.2ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 145.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 144.6ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 144.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 145.5ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 145.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 146.3ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 146.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 145.0ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 145.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 145.3ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 145.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 148.3ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 148.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 193.1ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 193.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 165.6ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 2.2ms preprocess, 165.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 169.4ms\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Speed: 2.1ms preprocess, 169.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 163.0ms\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Speed: 1.9ms preprocess, 163.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 169.4ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 2.5ms preprocess, 169.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 200.2ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 3.8ms preprocess, 200.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 168.0ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 162.7ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 162.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 156.5ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 156.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 168.3ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 168.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 155.6ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 2.4ms preprocess, 155.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 156.9ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 156.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 152.9ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 152.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 153.0ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 153.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 152.7ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 152.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 150.3ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 150.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 149.8ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 149.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 149.5ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 149.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 156.7ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 156.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 154.1ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 154.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 149.1ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 149.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 155.9ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 155.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 153.8ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 153.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 154.1ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 154.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 153.8ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 153.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 152.2ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 152.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 147.4ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 147.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 144.1ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 2.3ms preprocess, 144.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 145.8ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 145.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 149.1ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 149.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 145.1ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 145.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 146.1ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 146.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 142.7ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 151.0ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 153.8ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 153.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 151.9ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.9ms preprocess, 151.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 157.2ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 157.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 166.5ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 166.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 156.7ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 156.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 156.8ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 156.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 157.9ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 157.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 159.4ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 159.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 164.2ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 164.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 156.5ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 156.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 155.1ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 155.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 150.8ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 150.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 145.7ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 145.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 148.0ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 148.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 147.3ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 147.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 147.6ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 147.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 148.6ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.9ms preprocess, 148.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 150.2ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 150.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 151.5ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 151.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 apples, 1 mouse, 150.0ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 150.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 155.3ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 155.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 sink, 1 scissors, 151.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 151.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 1 scissors, 154.3ms\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 154.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 150.5ms\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 150.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 apple, 1 mouse, 1 scissors, 152.6ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 152.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 1 scissors, 151.4ms\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 151.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 1 scissors, 152.7ms\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 152.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 3 scissorss, 153.1ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 153.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 149.8ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 149.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 152.3ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 152.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 151.1ms\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 151.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 2 scissorss, 153.6ms\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 153.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 153.7ms\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 153.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 153.6ms\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 153.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 152.2ms\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 152.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 151.6ms\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 151.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 153.8ms\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 153.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 152.9ms\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 151.4ms\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 151.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 2 scissorss, 192.9ms\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 192.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 mouse, 2 scissorss, 167.6ms\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 2.0ms preprocess, 167.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 apple, 1 mouse, 1 scissors, 154.5ms\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 154.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 152.2ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 152.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 150.6ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Speed: 2.0ms preprocess, 150.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 1 mouse, 1 scissors, 151.5ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 151.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 151.9ms\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 151.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 151.5ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 151.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 152.4ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 152.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 153.2ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 153.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 151.8ms\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 151.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 151.7ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 151.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 155.5ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.9ms preprocess, 155.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 169.6ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 169.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 169.9ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 2.0ms preprocess, 169.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 155.9ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 155.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 157.8ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 157.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 154.9ms\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 154.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 158.1ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 158.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 164.0ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 164.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 166.9ms\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 166.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 156.7ms\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 156.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 162.5ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 162.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 154.2ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 154.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 169.5ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.4ms preprocess, 169.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 153.4ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 153.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 176.5ms\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 176.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 183.9ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 183.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 160.9ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 160.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 154.7ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 154.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 153.6ms\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Speed: 1.8ms preprocess, 153.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 158.4ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 158.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 182.3ms\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 182.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 198.4ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 198.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 174.2ms\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 174.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 184.0ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.7ms preprocess, 184.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 scissors, 162.5ms\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Speed: 1.9ms preprocess, 162.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 159.1ms\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 159.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 162.5ms\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Speed: 1.5ms preprocess, 162.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 mouse, 1 cell phone, 1 scissors, 167.2ms\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Speed: 1.6ms preprocess, 167.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m model(img, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Procesamos los resultados de la detección\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Iteramos sobre las cajas delimitadoras detectadas\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/autobackend.py:455\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 455\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    129\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:230\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 230\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:230\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 230\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:340\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    339\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/UHE/2024 Maestría IA Aplicada/Notebooks_PercepcionComputacional/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configuramos la captura de video desde la cámara\n",
    "captura = cv2.VideoCapture(0) # Se abre la cámara por defecto\n",
    "\n",
    "# Establecemos el ancho y alto de la imagen\n",
    "captura.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # Ancho de la imagen\n",
    "captura.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # Alto de la imagen\n",
    "\n",
    "# Iniciamos un bucle para procesar los fotogramas de la cámara\n",
    "while True:\n",
    "    success, img = captura.read() # Capturamos un fotograma\n",
    "\n",
    "    # Realizamos la detección de objetos en la imagen capturada (usando el modelo de YOLO pre-entrenado que cargamos anteriormente)\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # Procesamos los resultados de la detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Iteramos sobre las cajas delimitadoras detectadas\n",
    "        for box in boxes:\n",
    "            # Obtenemos el nombre de la clase detectada\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            # Solo procesamos la detección si la clase es de interés\n",
    "            if cls in clases_interes:\n",
    "                # Obtenemos las coordenadas de la caja delimitadora\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # Convertimos a valores enteros\n",
    "\n",
    "                # Dibujamos la caja delimitadora en la imagen\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)\n",
    "\n",
    "                # Obtenemos la confianza de la detección\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confidence --->\",confidence)\n",
    "\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                # Mostramos el nombre de la clase junto a la caja delimitadora\n",
    "                org = [x1, y1]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 1\n",
    "                color = (255, 0, 0) # Color: Azul (formato BGR)\n",
    "                thickness = 1\n",
    "                cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    # Mostramos la imagen con las detecciones\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # Salimos del bucle si se presiona la tecla 'q'\n",
    "    #if cv2.waitKey(1) == ord('q'):\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la cámara y cerramos todas las ventanas\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea: Aplicación de detección de objetos específicos con YOLO**\n",
    "\n",
    "Objetivo: Modificar el script de detección de objetos en tiempo real con YOLO para que solo detecte ciertas clases de objetos. Luego, darle una aplicación específica a esta detección.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "1. Elija un subconjunto de las 80 clases disponibles en YOLO que sean relevantes para una aplicación específica. Por ejemplo, si está creando una aplicación para ayudar a los conductores a detectar peatones y vehículos, podría elegir las clases 'persona', 'bicicleta', 'coche', 'moto', 'autobús' y 'camión'.\n",
    "\n",
    "2. Modifique el script de detección de objetos en tiempo real para que solo detecte las clases que ha seleccionado. Para hacer esto, necesitará crear una lista de los índices de las clases que ha selecciono y luego agregar una condición en el bucle donde se procesan los resultados de la detección para solo procesar las detecciones que corresponden a las clases seleccionadas.\n",
    "\n",
    "3. Pruebe su script modificado para asegurarse de que solo está detectando las clases que ha seleccionado.\n",
    "\n",
    "4. Piense en una aplicación específica para su detección de objetos. ¿Cómo podría usar la información de las detecciones para ayudar al usuario? Por ejemplo, en la aplicación para conductores, podría alertar al usuario si detecta un peatón o un vehículo en una zona de peligro.\n",
    "\n",
    "5. En clase, presente las clases que seleccionó, cómo modificó el script de detección de objetos, los resultados de sus pruebas, la aplicación específica que ha ideado para su detección de objetos, y cómo la aplicación serviría al usuario final u organización."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
